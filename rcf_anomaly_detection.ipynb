{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing csv file and editing it to ahve another column  - experiment 1 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "input_file_name = 'DryerPerformance_03.csv'  # Name of your input CSV file\n",
    "output_file_name = 'DryerPerformance_03-output.csv'  # Name of the output CSV file with the additional column\n",
    "column_name = 'Dryer1LbsPerHr'  # The column based on whose values you're adding a 1 or 0\n",
    "new_column_name = 'RunningOptimally'  # Name of the new column to be added\n",
    "\n",
    "# Read the input CSV file and write to the output CSV file with the additional column\n",
    "with open(input_file_name, mode='r', newline='') as infile, open(output_file_name, mode='w', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames + [new_column_name]  # Add the new column name to the fieldnames\n",
    "    \n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for row in reader:\n",
    "        # Check the condition for the specific column and set the value of the new column accordingly\n",
    "        # Adjust the condition below according to your requirements\n",
    "        if float(row[column_name]) > 30000:\n",
    "            row[new_column_name] = '1'\n",
    "        else:\n",
    "            row[new_column_name] = '0'\n",
    "        \n",
    "        writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experiment 2 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'DryerPerformance_03-output.csv'  # Update this to the path of your CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# If necessary, convert your date column to datetime and sort by date\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])  # Replace 'Date' with your actual date column name\n",
    "data.sort_values('DateTime', inplace=True)\n",
    "\n",
    "# Replace 'Value' with the name of the column you want to analyze for anomalies\n",
    "column_name = 'Value'  # Update this to the name of your feature column\n",
    "\n",
    "# Isolation Forest for anomaly detection\n",
    "model = IsolationForest(n_estimators=100, contamination=0.02, random_state=42)\n",
    "data['anomaly'] = model.fit_predict(data[[column_name]])\n",
    "\n",
    "# Visualize the data along with the anomalies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['Date'], data[column_name], color='blue', label='Normal')\n",
    "plt.scatter(data['Date'][data['anomaly'] == -1], data[column_name][data['anomaly'] == -1], color='red', label='Anomaly')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(column_name)\n",
    "plt.title('Time Series Anomaly Detection')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'DryerPerformance_03-output.csv'  # Update this with your actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming 'DateTime' is your datetime column and should be sorted\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "data.sort_values('DateTime', inplace=True)\n",
    "\n",
    "# Exclude 'RunningOptimally' from features to analyze\n",
    "features = data.columns.drop(['DateTime', 'RunningOptimally'])\n",
    "\n",
    "# Dictionary to hold anomaly counts for each feature\n",
    "anomaly_counts = {}\n",
    "\n",
    "for feature in features:\n",
    "    # Isolation Forest model\n",
    "    model = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "    # Fit model on the feature\n",
    "    anomalies = model.fit_predict(data[[feature]])\n",
    "    # Convert anomalies to a binary flag (1 for anomaly, 0 for normal)\n",
    "    anomaly_flags = (anomalies == -1).astype(int)\n",
    "    \n",
    "    # Compare detected anomalies with 'RunningOptimally' to see alignment\n",
    "    comparison = anomaly_flags == data['RunningOptimally']\n",
    "    # Count how many times anomalies align with 'RunningOptimally'=0\n",
    "    anomaly_counts[feature] = comparison.value_counts().get(False, 0)\n",
    "\n",
    "# Sort features based on count of aligned anomalies\n",
    "sorted_anomaly_counts = sorted(anomaly_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print features ranked by their alignment with 'RunningOptimally'\n",
    "for feature, count in sorted_anomaly_counts:\n",
    "    print(f\"Feature: {feature}, Anomaly Alignments: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experiment 3 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45474\n",
      "           1       1.00      1.00      1.00    154526\n",
      "\n",
      "    accuracy                           1.00    200000\n",
      "   macro avg       1.00      1.00      1.00    200000\n",
      "weighted avg       1.00      1.00      1.00    200000\n",
      "\n",
      "Accuracy: 0.998035\n",
      "Feature ranking by permutation importance:\n",
      "Dryer1LbsPerHr: 0.3488\n",
      "Sec2RetAirTemp: 0.0000\n",
      "Sec3SupAirTemp: 0.0000\n",
      "Zone2Sec5SteamSupPress: 0.0000\n",
      "Zone1BeltSpeed_1hz: 0.0000\n",
      "Sec6RetAirTemp: 0.0000\n",
      "Sec6SupplyAirTemp: 0.0000\n",
      "Zone1RetAirAvgTemp: 0.0000\n",
      "Zone2SupAirAvgTemp: 0.0000\n",
      "Sec9DeltaT: 0.0000\n",
      "Zone3Sec9SteamSupPress: 0.0000\n",
      "ThruputTotalShift: 0.0000\n",
      "Zone2RetAirAvgTemp: 0.0000\n",
      "Sec6SupplyAirSetpoint: 0.0000\n",
      "Sec5DeltaT: 0.0000\n",
      "Sec3DeltaT: 0.0000\n",
      "Sec9RetAirTemp: 0.0000\n",
      "Sec9SupplyAirTemp: 0.0000\n",
      "Zone1SupAirAvgTemp: 0.0000\n",
      "Sec4DeltaT: 0.0000\n",
      "Sec1DeltaT: 0.0000\n",
      "OutfeedMoisture: 0.0000\n",
      "Sec6SteamSupplyContValve: 0.0000\n",
      "Zone3Sec8SteamSupPress: 0.0000\n",
      "Sec4SupplyAirTempTE2031: 0.0000\n",
      "Zone3ExhaustMoisture: 0.0000\n",
      "Sec7DeltaT: 0.0000\n",
      "Zone2SteamSupFlow: 0.0000\n",
      "HumidityZone3: 0.0000\n",
      "Sec8DeltaT: 0.0000\n",
      "Sec4MainCoilSteamSupplyContValve: 0.0000\n",
      "Sec5SupplyAirTemp: 0.0000\n",
      "Sec6DeltaT: 0.0000\n",
      "InfeedMoisture: 0.0000\n",
      "Zone2SteamSupplyTemp: 0.0000\n",
      "Zone2ExhaustTemp: 0.0000\n",
      "Sec9SteamSupplyContValve: 0.0000\n",
      "MatHeightEast: 0.0000\n",
      "Zone1MatHeightAvg: 0.0000\n",
      "Zone3SupAirAvgTemp: 0.0000\n",
      "Zone1SupAirTemp: 0.0000\n",
      "Zone1SteamSupplyContValve: 0.0000\n",
      "Sec1SupAirTemp: 0.0000\n",
      "Zone3Sec7SteamSupPress: 0.0000\n",
      "Zone1SteamSupPress: 0.0000\n",
      "Sec2DeltaT: 0.0000\n",
      "Sec8RetAirTemp: 0.0000\n",
      "Sec7SupplyAirTemp: 0.0000\n",
      "Zone2RetChamberPressure: 0.0000\n",
      "Zone3RetAirAvgTemp: 0.0000\n",
      "Zone1SteamSupplyTemp: 0.0000\n",
      "Sec7MainCoilSupplyAirTempSetpoint: 0.0000\n",
      "MatHeightWest: 0.0000\n",
      "Zone1SteamSupFlow: 0.0000\n",
      "HumidityZone2: 0.0000\n",
      "Sec7BoosterCoilSteamSupplyContValve: 0.0000\n",
      "MpcConstrValve: 0.0000\n",
      "Sec1RetAirTemp: 0.0000\n",
      "Zone3SteamSupPress: 0.0000\n",
      "Sec9SupplyAirSetpoint: 0.0000\n",
      "Sec4BoosterCoilSupplyAirTempSetpoint: 0.0000\n",
      "Zone1AvgSupplySteamTempTE2225: 0.0000\n",
      "MakeUpAirFanOnOff: 0.0000\n",
      "Zone1EhaustTemp: 0.0000\n",
      "Speed: 0.0000\n",
      "HumidityZone1: 0.0000\n",
      "Dryer1Running: 0.0000\n",
      "Sec7SupplyAirMpcTempSP: 0.0000\n",
      "Sec1WestFanLow: 0.0000\n",
      "Sec1WestFanHigh: 0.0000\n",
      "MoistureTarget: 0.0000\n",
      "Dryer1Zone1SteamSupContValveOUT: 0.0000\n",
      "Zone1ExhaustMoistureSetpoint: 0.0000\n",
      "MpcMcSpDryer1: 0.0000\n",
      "WetBinLaserLevelEast: 0.0000\n",
      "WetBinLaserLevelWest: 0.0000\n",
      "Sec7SupplyAirTempSP: 0.0000\n",
      "Sec4SupplyAirTempTE2033: 0.0000\n",
      "MpcConstrTemp: 0.0000\n",
      "MpcConstrSteam: 0.0000\n",
      "MpcConstrWetBin: 0.0000\n",
      "MpcOnDryer1: 0.0000\n",
      "MoistureControlManual: 0.0000\n",
      "Zone1MakeupAirDamper: 0.0000\n",
      "Zone3ExhaustTemp: 0.0000\n",
      "Zone2RetChamberPressSetpoint: 0.0000\n",
      "Zone2PressureOUT: 0.0000\n",
      "Zone3BeltSpeed_1hz: 0.0000\n",
      "Zone3ConveyorSpeedAdjustment: 0.0000\n",
      "Zone3ExhaustAirDamperControl: 0.0000\n",
      "Zone2PressureSP: 0.0000\n",
      "Zone3ExhaustMoistureSetpoint: 0.0000\n",
      "Zone3ExitBeltSpeed: 0.0000\n",
      "Zone2MatHeight: 0.0000\n",
      "Zone3MakeupAirDamper: 0.0000\n",
      "Zone3MakeupAirTemp: 0.0000\n",
      "Zone3MatHeight: 0.0000\n",
      "Zone_3_Return_Chamber_Pressure: 0.0000\n",
      "Zone3RetChamberPressSetpoint: 0.0000\n",
      "Zone2PressurePV: 0.0000\n",
      "SpeedLimitHz: 0.0000\n",
      "FlakerFeedingWB1: 0.0000\n",
      "WetBinLevel: 0.0000\n",
      "Zone2MakeupAirTemp: 0.0000\n",
      "Zone2ExhaustMoistureSetpoint: 0.0000\n",
      "Zone1HzActWithMat: 0.0000\n",
      "Zone1RetChamberPress: 0.0000\n",
      "Zone1RetChamberPressSetpoint: 0.0000\n",
      "Zone1SteamSupplySetpoint: 0.0000\n",
      "Zone2BeltSpeed_1hz: 0.0000\n",
      "Zone2ConveyorSpeedAdjustment: 0.0000\n",
      "Zone2ExhaustAirDamperControl: 0.0000\n",
      "Zone2ExhaustMoisture: 0.0000\n",
      "Zone1ExhaustAirDamperControl: 0.0000\n",
      "Zone2MakeupAirDamper: 0.0000\n",
      "Zone2Sec4SteamSupPress: -0.0000\n",
      "OutfeedMoistureMW: -0.0000\n",
      "Zone1ExhaustMoisture: -0.0000\n",
      "Zone1SupAirSetpoint: -0.0000\n",
      "Sec4RetAirTemp: -0.0000\n",
      "Sec8SupplyAirSetpoint: -0.0000\n",
      "Sec4MainCoilSupplyAirTempSetpoint: -0.0000\n",
      "ThruputCurrent: -0.0000\n",
      "Sec5SteamSupplyContValve: -0.0000\n",
      "Sec5SupplyAirSetpoint: -0.0000\n",
      "Zone3SteamSupplyTemp: -0.0000\n",
      "Dryer1MaxBeltSpeed: -0.0000\n",
      "Sec4BoosterCoilSteamSupplyContValve: -0.0000\n",
      "Zone3SteamSupFlow: -0.0000\n",
      "Sec7BoosterCoilSupplyAirTempSetpoint: -0.0000\n",
      "Sec2SupAirTemp: -0.0000\n",
      "Zone1ConveyorSpeedRef: -0.0000\n",
      "Sec8SupplyAirTemp: -0.0000\n",
      "Sec7RetAirTemp: -0.0000\n",
      "Sec8SteamSupplyContValve: -0.0000\n",
      "Sec5RetAirTemp: -0.0000\n",
      "Zone2SteamSupPress: -0.0000\n",
      "Sec3RetAirTemp: -0.0000\n",
      "WetBinSpeed: -0.0000\n",
      "Sec7MainCoilSteamSupplyContValve: -0.0000\n",
      "Zone1MakeupAirTemp: -0.0000\n",
      "Zone2Sec6SteamSupPress: -0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'DryerPerformance_03-output.csv'  # Update this with your actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming 'DateTime' is your datetime column and should be sorted\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "data.sort_values('DateTime', inplace=True)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = data.drop(['DateTime', 'RunningOptimally'], axis=1)\n",
    "y = data['RunningOptimally']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the HistGradientBoostingClassifier\n",
    "model = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "# Compute permutation importance\n",
    "perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "# Get sorted feature importances\n",
    "sorted_idx = perm_importance.importances_mean.argsort()[::-1]\n",
    "\n",
    "# Print features ranked by their permutation importance\n",
    "print(\"Feature ranking by permutation importance:\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{X.columns[i]}: {perm_importance.importances_mean[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experiment number 4 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Feature  AnomaliesCount\n",
      "0          Zone_3_Return_Chamber_Pressure           42785\n",
      "1                       Zone1SteamSupFlow           35857\n",
      "2                     Sec7SupplyAirTempSP           32409\n",
      "3                  Sec7SupplyAirMpcTempSP           32409\n",
      "4    Sec7BoosterCoilSupplyAirTempSetpoint           32403\n",
      "5                     Zone1SupAirSetpoint           32223\n",
      "6                   Zone1ConveyorSpeedRef           28925\n",
      "7                      Zone1RetAirAvgTemp           25396\n",
      "8                             WetBinLevel           25065\n",
      "9                          Sec2RetAirTemp           24994\n",
      "10                         Sec1RetAirTemp           24673\n",
      "11               Sec9SteamSupplyContValve           23617\n",
      "12                         Sec3RetAirTemp           23565\n",
      "13                         MpcConstrValve           23133\n",
      "14                      Sec6SupplyAirTemp           22771\n",
      "15                         Sec1SupAirTemp           22753\n",
      "16                         Sec3SupAirTemp           22115\n",
      "17                     Zone1SupAirAvgTemp           21961\n",
      "18                     Zone2SupAirAvgTemp           21758\n",
      "19                        Zone1SupAirTemp           21573\n",
      "20               Sec5SteamSupplyContValve           21568\n",
      "21                         Sec2SupAirTemp           21538\n",
      "22                     Zone2BeltSpeed_1hz           20544\n",
      "23                     Zone3BeltSpeed_1hz           20479\n",
      "24                     Zone1BeltSpeed_1hz           20464\n",
      "25                     Zone1MakeupAirTemp           19691\n",
      "26                      Sec5SupplyAirTemp           19454\n",
      "27                      Sec7SupplyAirTemp           18700\n",
      "28                      Sec8SupplyAirTemp           18204\n",
      "29                         Sec6RetAirTemp           18170\n",
      "30                     Zone3SupAirAvgTemp           18027\n",
      "31                      Sec9SupplyAirTemp           17794\n",
      "32                         Sec9RetAirTemp           17630\n",
      "33                     Zone2RetAirAvgTemp           17578\n",
      "34                         Sec5RetAirTemp           17131\n",
      "35                     Zone3RetAirAvgTemp           17024\n",
      "36                         Sec4RetAirTemp           16944\n",
      "37                         Sec8RetAirTemp           16686\n",
      "38                       Zone3ExhaustTemp           16686\n",
      "39                Sec4SupplyAirTempTE2031           16677\n",
      "40                         Sec7RetAirTemp           16202\n",
      "41                          HumidityZone3           14421\n",
      "42                   Zone3ExhaustMoisture           14420\n",
      "43               Sec8SteamSupplyContValve           13971\n",
      "44                   Zone1SteamSupplyTemp           13568\n",
      "45                          MpcConstrTemp           11739\n",
      "46                 Zone2Sec4SteamSupPress           11114\n",
      "47                     Zone3SteamSupPress           11077\n",
      "48                   Zone2MakeupAirDamper           10457\n",
      "49    Sec7BoosterCoilSteamSupplyContValve            9608\n",
      "50                   Zone3SteamSupplyTemp            8717\n",
      "51                          HumidityZone2            8531\n",
      "52                        OutfeedMoisture            8522\n",
      "53                   Zone2SteamSupplyTemp            8450\n",
      "54       Sec7MainCoilSteamSupplyContValve            7947\n",
      "55                 Zone3Sec9SteamSupPress            7775\n",
      "56                      OutfeedMoistureMW            7773\n",
      "57               Sec6SteamSupplyContValve            7555\n",
      "58                 Zone3Sec7SteamSupPress            7447\n",
      "59                             Sec7DeltaT            7242\n",
      "60                 Zone3Sec8SteamSupPress            7043\n",
      "61                      ThruputTotalShift            6400\n",
      "62                             Sec8DeltaT            5868\n",
      "63                            WetBinSpeed            5327\n",
      "64                       Zone2ExhaustTemp            5192\n",
      "65                             Sec9DeltaT            5080\n",
      "66                             Sec3DeltaT            4372\n",
      "67                      Zone3SteamSupFlow            4355\n",
      "68                             Sec6DeltaT            4082\n",
      "69                             Sec2DeltaT            3790\n",
      "70                             Sec1DeltaT            3260\n",
      "71                 Zone2Sec6SteamSupPress            2421\n",
      "72           Zone3ExhaustAirDamperControl            1427\n",
      "73                             Sec5DeltaT            1407\n",
      "74                             Sec4DeltaT            1209\n",
      "75                           SpeedLimitHz             811\n",
      "76                 Zone2Sec5SteamSupPress             794\n",
      "77                      Zone2SteamSupFlow             721\n",
      "78                          HumidityZone1             302\n",
      "79                   Zone1ExhaustMoisture             292\n",
      "80                   WetBinLaserLevelWest             161\n",
      "81                   Zone1RetChamberPress             152\n",
      "82           Zone2ExhaustAirDamperControl              14\n",
      "83                          MatHeightWest               8\n",
      "84                      Zone1HzActWithMat               5\n",
      "85                          MatHeightEast               2\n",
      "86                      Zone1MatHeightAvg               2\n",
      "87                  Sec5SupplyAirSetpoint               1\n",
      "88                     Dryer1MaxBeltSpeed               1\n",
      "89                         MoistureTarget               0\n",
      "90    Sec4BoosterCoilSteamSupplyContValve               0\n",
      "91   Sec4BoosterCoilSupplyAirTempSetpoint               0\n",
      "92       Sec4MainCoilSteamSupplyContValve               0\n",
      "93      Sec4MainCoilSupplyAirTempSetpoint               0\n",
      "94                Sec4SupplyAirTempTE2033               0\n",
      "95                  Sec6SupplyAirSetpoint               0\n",
      "96      Sec7MainCoilSupplyAirTempSetpoint               0\n",
      "97                  Sec8SupplyAirSetpoint               0\n",
      "98                  Sec9SupplyAirSetpoint               0\n",
      "99                                  Speed               0\n",
      "100                        ThruputCurrent               0\n",
      "101         Zone1AvgSupplySteamTempTE2225               0\n",
      "102                       Zone1EhaustTemp               0\n",
      "103          Zone1ExhaustAirDamperControl               0\n",
      "104          Zone1ExhaustMoistureSetpoint               0\n",
      "105                  Zone1MakeupAirDamper               0\n",
      "106          Zone1RetChamberPressSetpoint               0\n",
      "107             Zone1SteamSupplyContValve               0\n",
      "108              Zone1SteamSupplySetpoint               0\n",
      "109                    Zone1SteamSupPress               0\n",
      "110          Zone2ConveyorSpeedAdjustment               0\n",
      "111                  Zone2ExhaustMoisture               0\n",
      "112          Zone2ExhaustMoistureSetpoint               0\n",
      "113                    Zone2MakeupAirTemp               0\n",
      "114                        Zone2MatHeight               0\n",
      "115          Zone2RetChamberPressSetpoint               0\n",
      "116               Zone2RetChamberPressure               0\n",
      "117                    Zone2SteamSupPress               0\n",
      "118          Zone3ConveyorSpeedAdjustment               0\n",
      "119          Zone3ExhaustMoistureSetpoint               0\n",
      "120                    Zone3ExitBeltSpeed               0\n",
      "121                  Zone3MakeupAirDamper               0\n",
      "122                    Zone3MakeupAirTemp               0\n",
      "123                        Zone3MatHeight               0\n",
      "124          Zone3RetChamberPressSetpoint               0\n",
      "125                 MoistureControlManual               0\n",
      "126                       Zone2PressurePV               0\n",
      "127                       Zone2PressureSP               0\n",
      "128                      Zone2PressureOUT               0\n",
      "129                      FlakerFeedingWB1               0\n",
      "130                     MakeUpAirFanOnOff               0\n",
      "131                         Dryer1Running               0\n",
      "132                        InfeedMoisture               0\n",
      "133                        Sec1WestFanLow               0\n",
      "134                       Sec1WestFanHigh               0\n",
      "135       Dryer1Zone1SteamSupContValveOUT               0\n",
      "136                           MpcOnDryer1               0\n",
      "137                         MpcMcSpDryer1               0\n",
      "138                  WetBinLaserLevelEast               0\n",
      "139                        MpcConstrSteam               0\n",
      "140                       MpcConstrWetBin               0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 4000\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('DryerPerformance_03-output.csv')\n",
    "\n",
    "# Filter rows where 'RunningOptimally' is 0\n",
    "df_not_optimal = df[df['RunningOptimally'] == 0]\n",
    "\n",
    "# Initialize a dictionary to hold the count of anomalies for each feature\n",
    "anomalies_count = {}\n",
    "\n",
    "# Define an anomaly threshold (e.g., 2 standard deviations from the mean)\n",
    "threshold = 2\n",
    "\n",
    "# Loop through each feature column (excluding 'DateTime' and 'RunningOptimally')\n",
    "for column in df_not_optimal.columns.drop(['DateTime', 'RunningOptimally', 'Dryer1LbsPerHr']):\n",
    "    # Calculate the mean and standard deviation for the column\n",
    "    mean = df_not_optimal[column].mean()\n",
    "    std = df_not_optimal[column].std()\n",
    "    \n",
    "    # Define what is considered an anomaly (outside of threshold standard deviations)\n",
    "    lower_bound = mean - threshold * std\n",
    "    upper_bound = mean + threshold * std\n",
    "    \n",
    "    # Count how many values fall outside of the bounds (anomalies)\n",
    "    anomalies = df_not_optimal[(df_not_optimal[column] < lower_bound) | (df_not_optimal[column] > upper_bound)]\n",
    "    anomalies_count[column] = len(anomalies)\n",
    "\n",
    "# Sort the dictionary by the count of anomalies in descending order\n",
    "sorted_anomalies = sorted(anomalies_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Convert to DataFrame for better visualization (optional)\n",
    "sorted_anomalies_df = pd.DataFrame(sorted_anomalies, columns=['Feature', 'AnomaliesCount'])\n",
    "\n",
    "# Display the sorted list of features by anomalies count\n",
    "print(sorted_anomalies_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection for SaaS metrics using Random Cut Forests (RCF)\n",
    "***\n",
    "\n",
    "## Introduction\n",
    "Amazon SageMaker Random Cut Forest (RCF) is an unsupervised algorithm for detecting anomalous data points within a data set. These are observations which diverge from otherwise well-structured or patterned data. Anomalies can manifest as unexpected spikes in time series data, breaks in periodicity, or unclassifiable data points. They are easy to describe in that, when viewed in a plot, they are often easily distinguishable from the \"regular\" data. Including these anomalies in a data set can drastically increase the complexity of a machine learning task since the \"regular\" data can often be described with a simple model.\n",
    "\n",
    "Find the documentation [here](https://docs.aws.amazon.com/sagemaker/latest/dg/randomcutforest.html).\n",
    "\n",
    "Deep dive video about RCF https://www.youtube.com/watch?v=9BWHR4JsTNU\n",
    "\n",
    "This notebook is based on the [\"Introduction to RCF\" notebook](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/random_cut_forest/random_cut_forest.ipynb). If you want more details on what is done here, feel free to check it out.\n",
    "\n",
    "\n",
    "\n",
    "## Setup\n",
    "*This notebook was tested in Amazon SageMaker Studio instance with Python 3 (conda_python3 kernel).*\n",
    "\n",
    "\n",
    "First, ensure Sagemaker has read access to S3 and Athena.\n",
    "Then adjust the following values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (619133805.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    s3_bucket = # \"USERNAME-tenant-metrics\" # an Amazon S3 bucket accessible by your account\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# TODO: adjust s3_bucket and athena_db\n",
    "s3_bucket = # \"USERNAME-tenant-metrics\" # an Amazon S3 bucket accessible by your account \n",
    "s3_prefix = \"sagemaker/rcf\"\n",
    "athena_db = \"\\\"tenants-metrics\\\".\\\"sample_data\\\"\" #Adjust athena_db if needed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding import of system required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyAthena\n",
      "  Downloading pyathena-3.2.1-py3-none-any.whl.metadata (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: boto3>=1.26.4 in /Users/clastinger/Library/Python/3.9/lib/python/site-packages (from PyAthena) (1.28.60)\n",
      "Requirement already satisfied: botocore>=1.29.4 in /Users/clastinger/Library/Python/3.9/lib/python/site-packages (from PyAthena) (1.31.60)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /Users/clastinger/Library/Python/3.9/lib/python/site-packages (from PyAthena) (8.2.3)\n",
      "Requirement already satisfied: fsspec in /Users/clastinger/Library/Python/3.9/lib/python/site-packages (from PyAthena) (2023.9.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/clastinger/Library/Python/3.9/lib/python/site-packages (from boto3>=1.26.4->PyAthena) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /Users/clastinger/Library/Python/3.9/lib/python/site-packages (from boto3>=1.26.4->PyAthena) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/clastinger/Library/Python/3.9/lib/python/site-packages (from botocore>=1.29.4->PyAthena) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/clastinger/Library/Python/3.9/lib/python/site-packages (from botocore>=1.29.4->PyAthena) (1.26.17)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.29.4->PyAthena) (1.15.0)\n",
      "Downloading pyathena-3.2.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyAthena\n",
      "Successfully installed PyAthena-3.2.1\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomCutForest, Session, get_execution_role\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# graphs\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     18\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# aws\n",
    "import boto3\n",
    "import botocore\n",
    "#!conda install --yes --prefix {sys.prefix} PyAthena\n",
    "!{sys.executable} -m pip install PyAthena\n",
    "from pyathena import connect\n",
    "import sagemaker\n",
    "from sagemaker import RandomCutForest, Session, get_execution_role\n",
    "\n",
    "# graphs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize session\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "execution_role = get_execution_role()\n",
    "\n",
    "# define paths\n",
    "s3_query_results = f's3://{s3_bucket}/{s3_prefix}/query-results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the bucket exists\n",
    "try:\n",
    "    boto3.Session().client('s3').head_bucket(Bucket=s3_bucket)\n",
    "except botocore.exceptions.ParamValidationError as e:\n",
    "    print('Hey! You either forgot to specify your S3 bucket'\n",
    "          ' or you gave your bucket an invalid name!')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == '403':\n",
    "        print(\"Hey! You don't have permission to access the bucket, {}.\".format(s3_bucket))\n",
    "    elif e.response['Error']['Code'] == '404':\n",
    "        print(\"Hey! Your bucket, {}, doesn't exist!\".format(s3_bucket))\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    print('Training input/output will be stored in: s3://{}/{}'.format(s3_bucket, s3_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying S3 using Athena\n",
    "The query gets the storage consumption per day of a certain tenant sorted by time. \n",
    "You can read more about querying S3 using Athena from Sagemaker over [here](https://aws.amazon.com/blogs/machine-learning/run-sql-queries-from-your-sagemaker-notebooks-using-amazon-athena/).\n",
    "\n",
    "When plotting the data, it becomes clear that there are indeed some anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect(s3_staging_dir=s3_query_results, region_name=region)\n",
    "\n",
    "# queries the storage consumption per day of tenant 3\n",
    "query = f\"\"\"\n",
    "WITH storage_consumption AS(\n",
    "    SELECT\n",
    "        date_trunc('day', from_unixtime(timestamp)) AS timestamp,\n",
    "        metric.value                                AS storage\n",
    "    FROM\n",
    "        { athena_db }\n",
    "    WHERE\n",
    "        metric.name = 'Storage'\n",
    "        AND\n",
    "            tenant.id = 'tenant-id-3'\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    storage_consumption.timestamp,\n",
    "    sum(storage)                   AS storage\n",
    "FROM \n",
    "    storage_consumption\n",
    "GROUP BY\n",
    "    storage_consumption.timestamp\n",
    "ORDER BY\n",
    "    storage_consumption.timestamp ASC\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn, index_col=\"timestamp\", parse_dates=\"timestamp\")\n",
    "df = df[1:-1] # skip first and last day, because only half the day was monitored\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Sagemaker and RCFs\n",
    "Setup sagemaker to store the training releated data to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "\n",
    "# specify general training job information\n",
    "rcf = RandomCutForest(role=execution_role,\n",
    "                      instance_count=3,\n",
    "                      instance_type='ml.m4.xlarge',\n",
    "                      use_spot_instances=True,  # Use a spot instance \n",
    "                      max_run=300,  # Max training time\n",
    "                      max_wait=600,  # Max training time + spot waiting time\n",
    "                      data_location='s3://{}/{}/{}/'.format(s3_bucket, s3_prefix, \"rcf\"),\n",
    "                      output_path='s3://{}/{}/{}/output'.format(s3_bucket, s3_prefix, \"rcf\"),\n",
    "                      num_samples_per_tree=512,\n",
    "                      num_trees=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCF Model Training\n",
    "Train the RCF on our data and publish an endpoint. This will take around 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# convert the data to a numpy array\n",
    "y = df.to_numpy()\n",
    "\n",
    "# automatically upload the training data to S3 and run the training job\n",
    "rcf.fit(rcf.record_set(y))\n",
    "print('Training job name: {}'.format(rcf.latest_training_job.job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Progress:\")\n",
    "rcf_inference = rcf.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    ")\n",
    "print('Endpoint name: {}'.format(rcf_inference.endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference\n",
    "Run the prediction through the endpoint with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = rcf_inference.predict(y)\n",
    "scores = [datum.label[\"score\"].float32_tensor.values[0] for datum in results]\n",
    "\n",
    "results = df.copy()\n",
    "results[\"score\"] = scores\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(results['storage'], color='C0', alpha=0.8)\n",
    "ax2.plot(results['score'], color='C1')\n",
    "\n",
    "ax1.grid(which='major', axis='both')\n",
    "\n",
    "ax1.set_ylabel('Storage Consumption', color='C0')\n",
    "ax2.set_ylabel('Anomaly Score', color='C1')\n",
    "\n",
    "ax1.tick_params('y', colors='C0')\n",
    "ax2.tick_params('y', colors='C1')\n",
    "\n",
    "ax2.set_ylim(min(scores), 1.4 * max(scores))\n",
    "fig.set_figwidth(16)\n",
    "\n",
    "score_mean = results['score'].mean()\n",
    "score_std = results['score'].std()\n",
    "score_cutoff = score_mean + 4 * score_std # adjust constant to tweak sensitivity\n",
    "\n",
    "anomalies = results[results['score'] > score_cutoff]\n",
    "ax2.plot(anomalies.index, anomalies.score, 'ko');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to delete the inference endpoint\n",
    "Session().delete_endpoint(rcf_inference.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
